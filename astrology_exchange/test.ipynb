{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEZBRRShsGwa",
        "outputId": "16686c51-83e0-44cd-ecdd-bdcc4fa94b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.1.1\n",
            "Collecting skyfield\n",
            "  Downloading skyfield-1.49-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from skyfield) (2024.12.14)\n",
            "Collecting jplephem>=2.13 (from skyfield)\n",
            "  Downloading jplephem-2.22-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from skyfield) (1.26.4)\n",
            "Collecting sgp4>=2.2 (from skyfield)\n",
            "  Downloading sgp4-2.23-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Downloading skyfield-1.49-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.2/336.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jplephem-2.22-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sgp4-2.23-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.3/232.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sgp4, jplephem, skyfield\n",
            "Successfully installed jplephem-2.22 sgp4-2.23 skyfield-1.49\n"
          ]
        }
      ],
      "source": [
        "!pip install pymysql\n",
        "!pip install skyfield"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymysql\n",
        "from sqlalchemy import create_engine\n",
        "from skyfield.api import load\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import pandas as pd\n",
        "import requests\n",
        "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import LSTM\n",
        "import json\n",
        "\n",
        "# Параметры подключения к базе данных\n",
        "db_config = {\n",
        "    \"host\": \"sql7.freemysqlhosting.net\",\n",
        "    \"user\": \"sql7753415\",\n",
        "    \"password\": \"XNjmZyasHS\",\n",
        "    \"database\": \"sql7753415\",\n",
        "    \"port\": 3306\n",
        "}\n",
        "\n",
        "DB_SERVER = \"sql7.freemysqlhosting.net\"\n",
        "DB_NAME = \"sql7753415\"\n",
        "DB_USER = \"sql7753415\"\n",
        "DB_PASSWORD = \"XNjmZyasHS\"\n",
        "DB_PORT = 3306\n",
        "\n",
        "\n",
        "\n",
        "BASE_URL = \"https://iss.moex.com/iss/history/engines/stock/markets/shares/securities\"\n",
        "\n",
        "def fetch_first_trading_day(company):\n",
        "\n",
        "    try:\n",
        "        response = requests.get(f\"{BASE_URL}/{company}.json\", params={\"iss.meta\": \"off\", \"lang\": \"ru\"})\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Парсинг данных\n",
        "        data = response.json()\n",
        "        history_data = data.get('history', {}).get('data', [])\n",
        "        history_columns = data.get('history', {}).get('columns', [])\n",
        "\n",
        "        # Преобразование в DataFrame\n",
        "        df = pd.DataFrame(history_data, columns=history_columns)\n",
        "\n",
        "        # Проверка и нахождение первой даты\n",
        "        if \"TRADEDATE\" in df.columns:\n",
        "            return df[\"TRADEDATE\"].min()\n",
        "        else:\n",
        "            raise ValueError(\"TRADEDATE колонка не найдена в данных.\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Ошибка при запросе первого дня торгов: {e}\")\n",
        "\n",
        "def fetch_historical_data(company, start_date):\n",
        "\n",
        "    all_data = []\n",
        "    start = 0\n",
        "    try:\n",
        "        while True:\n",
        "            # Параметры запроса\n",
        "            params = {\n",
        "                \"from\": start_date,\n",
        "                \"iss.meta\": \"off\",\n",
        "                \"start\": start,  # Пагинация\n",
        "                \"lang\": \"ru\"\n",
        "            }\n",
        "\n",
        "            response = requests.get(f\"{BASE_URL}/{company}.json\", params=params)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Парсинг данных\n",
        "            data = response.json()\n",
        "            history_data = data.get('history', {}).get('data', [])\n",
        "            history_columns = data.get('history', {}).get('columns', [])\n",
        "\n",
        "            if not history_data:\n",
        "                break  # Если данные закончились\n",
        "\n",
        "            df = pd.DataFrame(history_data, columns=history_columns)\n",
        "            all_data.append(df)\n",
        "\n",
        "            # Увеличение пагинации\n",
        "            start += 100\n",
        "\n",
        "        # Объединение всех данных\n",
        "        full_data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "        # Фильтрация данных\n",
        "        if \"TRADEDATE\" in full_data.columns and \"CLOSE\" in full_data.columns:\n",
        "            result_df = full_data[[\"TRADEDATE\", \"CLOSE\"]].rename(columns={\n",
        "                \"TRADEDATE\": \"date\",\n",
        "                \"CLOSE\": \"value\"\n",
        "            })\n",
        "            return result_df\n",
        "        else:\n",
        "            raise ValueError(\"Не найдены необходимые колонки (TRADEDATE и CLOSE).\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Ошибка при запросе исторических данных: {e}\")\n",
        "\n",
        "def company_stock_history(company):\n",
        "\n",
        "    try:\n",
        "        first_day = fetch_first_trading_day(company)\n",
        "        historical_data = fetch_historical_data(company, first_day)\n",
        "        return historical_data\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка: {e}\")\n",
        "        return None\n",
        "\n",
        "def merge_stock_with_astro(stock_data):\n",
        "\n",
        "    if 'date' not in stock_data.columns:\n",
        "        raise ValueError(\"Датасет 'stock_data' должен содержать столбец 'date'.\")\n",
        "\n",
        "    # Подключение к базе данных\n",
        "    engine = create_engine(f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_SERVER}:{DB_PORT}/{DB_NAME}\")\n",
        "\n",
        "    # Определяем диапазон дат из stock_data\n",
        "    start_date = stock_data['date'].min()\n",
        "    end_date = stock_data['date'].max()\n",
        "\n",
        "    # SQL-запрос для извлечения данных из таблицы astro в указанном диапазоне\n",
        "    query = f\"\"\"\n",
        "    SELECT *,\n",
        "           CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) AS full_date\n",
        "    FROM astro\n",
        "    WHERE CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) BETWEEN '{start_date}' AND '{end_date}';\n",
        "    \"\"\"\n",
        "\n",
        "    # Извлечение данных из базы данных\n",
        "    astro_data = pd.read_sql(query, engine)\n",
        "\n",
        "    # Приводим столбец full_date в astro_data к формату datetime\n",
        "    astro_data['full_date'] = pd.to_datetime(astro_data['full_date'])\n",
        "\n",
        "    # Приводим столбец date в stock_data к формату datetime\n",
        "    stock_data['date'] = pd.to_datetime(stock_data['date'])\n",
        "\n",
        "    # Объединяем stock_data с astro_data по столбцу \"date\" и \"full_date\"\n",
        "    eph_stock_data = pd.merge(stock_data, astro_data, left_on='date', right_on='full_date', how='left')\n",
        "\n",
        "    # Убираем вспомогательный столбец full_date\n",
        "    eph_stock_data = eph_stock_data.drop(columns=['full_date'])\n",
        "\n",
        "    return eph_stock_data"
      ],
      "metadata": {
        "id": "eifwFbFDtBgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_and_train_model_lstm(eph_stock_data, target_column='value', timesteps=30, epochs=20, batch_size=32):\n",
        "    # 1. Удаляем строки с NaN\n",
        "    eph_stock_data = eph_stock_data.dropna()\n",
        "\n",
        "    # 2. Удаляем ненужные столбцы\n",
        "    eph_stock_data = eph_stock_data.drop(columns=['date_x', 'date_y'], errors='ignore')\n",
        "\n",
        "    # 3. Масштабируем данные к диапазону [-1, 1], кроме целевого столбца\n",
        "    scaler = StandardScaler()\n",
        "    feature_columns = eph_stock_data.columns.difference([target_column])\n",
        "    eph_stock_data[feature_columns] = scaler.fit_transform(eph_stock_data[feature_columns])\n",
        "\n",
        "    # 4. Подготавливаем данные для LSTM\n",
        "    X, y = [], []\n",
        "    for i in range(len(eph_stock_data) - timesteps):\n",
        "        X.append(eph_stock_data.iloc[i:i+timesteps][feature_columns].values)\n",
        "        y.append(eph_stock_data.iloc[i+timesteps][target_column])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # 5. Создаем LSTM модель\n",
        "    input_shape = (X.shape[1], X.shape[2])  # (timesteps, features)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, activation='tanh', input_shape=input_shape, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(32, activation='tanh', return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))  # Предсказание одного значения\n",
        "    model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    # 6. Обучаем модель\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    model_checkpoint = ModelCheckpoint('best_lstm_model.keras', monitor='val_loss', save_best_only=True)\n",
        "    callbacks = [early_stopping, model_checkpoint]\n",
        "\n",
        "    model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
        "\n",
        "    return model, scaler\n",
        "\n",
        "def get_stock_predict_lstm(trained_model, scaler, stock_data, target_column='value', timesteps=30):\n",
        "    # 1. Подготовка данных эфемерид\n",
        "    engine = create_engine(f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_SERVER}:{DB_PORT}/{DB_NAME}\")\n",
        "    moscow_timezone = pytz.timezone(\"Europe/Moscow\")\n",
        "    current_time = datetime.now(moscow_timezone)\n",
        "\n",
        "    start_date = stock_data['date'].max() + pd.Timedelta(\"1 day\")\n",
        "    end_date = stock_data['date'].max() + pd.Timedelta(\"31 day\")\n",
        "\n",
        "    query = f\"\"\"\n",
        "    SELECT *,\n",
        "           CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) AS full_date\n",
        "    FROM astro\n",
        "    WHERE CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) BETWEEN '{start_date}' AND '{end_date}';\n",
        "    \"\"\"\n",
        "    astro_data = pd.read_sql(query, engine)\n",
        "    astro_data['date'] = pd.to_datetime(astro_data[['year', 'month', 'day']])\n",
        "\n",
        "    # 2. Объединяем данные\n",
        "    stock_data['date'] = pd.to_datetime(stock_data['date'])\n",
        "    merged_data = pd.merge(stock_data, astro_data, on='date', how='right')\n",
        "    merged_data = merged_data.drop(columns=['date', 'full_date', 'value'], errors='ignore')\n",
        "\n",
        "    feature_columns = merged_data.columns.difference([target_column])\n",
        "    merged_data[feature_columns] = scaler.transform(merged_data[feature_columns])\n",
        "\n",
        "    # 3. Подготовка временного окна для предсказания\n",
        "    initial_window = merged_data.iloc[-timesteps:][feature_columns].values\n",
        "    X_pred = np.array([initial_window])\n",
        "\n",
        "    # 4. Генерация предсказаний на 30 дней\n",
        "    predictions = []\n",
        "    for _ in range(30):\n",
        "        pred_value = trained_model.predict(X_pred)[0][0]\n",
        "        predictions.append(pred_value)\n",
        "        new_row = np.zeros((1, X_pred.shape[2]))\n",
        "        X_pred = np.concatenate([X_pred[:, 1:, :], new_row[np.newaxis, :, :]], axis=1)\n",
        "        X_pred[0, -1, :-1] = merged_data.iloc[-1][feature_columns]\n",
        "        X_pred[0, -1, -1] = pred_value\n",
        "\n",
        "    future_dates = [start_date + pd.Timedelta(f\"{i} day\") for i in range(30)]\n",
        "    prediction_df = pd.DataFrame({'date': future_dates, 'predicted_value': predictions})\n",
        "\n",
        "    return prediction_df\n",
        "\n",
        "def calculate(tiker):\n",
        "\n",
        "    stock_data = company_stock_history(tiker)\n",
        "    eph_stock_data = merge_stock_with_astro(stock_data)\n",
        "    trained_model, scaler = prepare_and_train_model_lstm(eph_stock_data)\n",
        "    predicted_prices = get_stock_predict_lstm(trained_model,scaler, stock_data)\n",
        "\n",
        "    return stock_data, predicted_prices\n",
        "\n",
        "def convert_dates_to_strings(df):\n",
        "\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = df['date'].astype(str)\n",
        "    return df"
      ],
      "metadata": {
        "id": "gFjzeX6bsQUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1, df2 = calculate(\"YDEX\")\n",
        "print(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2ViXhwKLsWhW",
        "outputId": "c7556199-9d48-4d13-d1a4-aa70a287edd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 259ms/step - loss: 14687503.0000 - mae: 3825.1250 - val_loss: 11761997.0000 - val_mae: 3424.4031\n",
            "Epoch 2/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 14648432.0000 - mae: 3820.0137 - val_loss: 11760277.0000 - val_mae: 3424.1489\n",
            "Epoch 3/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 14630211.0000 - mae: 3817.3826 - val_loss: 11758767.0000 - val_mae: 3423.9250\n",
            "Epoch 4/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 14541310.0000 - mae: 3805.8865 - val_loss: 11757532.0000 - val_mae: 3423.7407\n",
            "Epoch 5/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 14662460.0000 - mae: 3821.7427 - val_loss: 11755954.0000 - val_mae: 3423.5056\n",
            "Epoch 6/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 14700806.0000 - mae: 3826.5916 - val_loss: 11753741.0000 - val_mae: 3423.1765\n",
            "Epoch 7/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 14589060.0000 - mae: 3812.2188 - val_loss: 11752125.0000 - val_mae: 3422.9329\n",
            "Epoch 8/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 14636860.0000 - mae: 3818.6484 - val_loss: 11750854.0000 - val_mae: 3422.7375\n",
            "Epoch 9/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 14489619.0000 - mae: 3798.7551 - val_loss: 11749921.0000 - val_mae: 3422.5879\n",
            "Epoch 10/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 14525005.0000 - mae: 3804.0596 - val_loss: 11748753.0000 - val_mae: 3422.4026\n",
            "Epoch 11/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 14579159.0000 - mae: 3810.6128 - val_loss: 11747574.0000 - val_mae: 3422.2134\n",
            "Epoch 12/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 14591897.0000 - mae: 3812.3403 - val_loss: 11746239.0000 - val_mae: 3422.0022\n",
            "Epoch 13/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 14671318.0000 - mae: 3823.2869 - val_loss: 11744435.0000 - val_mae: 3421.7234\n",
            "Epoch 14/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 14492052.0000 - mae: 3799.2180 - val_loss: 11742310.0000 - val_mae: 3421.3984\n",
            "Epoch 15/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 14608997.0000 - mae: 3814.6392 - val_loss: 11739874.0000 - val_mae: 3421.0291\n",
            "Epoch 16/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 14472195.0000 - mae: 3796.3750 - val_loss: 11737390.0000 - val_mae: 3420.6536\n",
            "Epoch 17/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 14551140.0000 - mae: 3807.3086 - val_loss: 11735072.0000 - val_mae: 3420.3030\n",
            "Epoch 18/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 14639798.0000 - mae: 3819.0120 - val_loss: 11732994.0000 - val_mae: 3419.9900\n",
            "Epoch 19/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 14510514.0000 - mae: 3802.0735 - val_loss: 11731251.0000 - val_mae: 3419.7271\n",
            "Epoch 20/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 14520170.0000 - mae: 3803.1624 - val_loss: 11729770.0000 - val_mae: 3419.5042\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not broadcast input array from shape (27,) into shape (26,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e774d3eb5a8f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"YDEX\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b770d1b00376>\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(tiker)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0meph_stock_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_stock_with_astro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_and_train_model_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meph_stock_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mpredicted_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stock_predict_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_prices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b770d1b00376>\u001b[0m in \u001b[0;36mget_stock_predict_lstm\u001b[0;34m(trained_model, scaler, stock_data, target_column, timesteps)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mnew_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mX_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mX_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mX_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (27,) into shape (26,)"
          ]
        }
      ]
    }
  ]
}